{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn import impute\n",
    "\n",
    "import keras_tuner\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"E:\\BANGKIT2022\\CapstoneProject\\data_gathering\\data\\cleaned_data.csv\"\n",
    "\n",
    "dataframe = pd.read_csv(csv_file, delimiter=';')\n",
    "dataframecopy = pd.read_csv(csv_file, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food_Name</th>\n",
       "      <th>Energi</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Karbohidrat_total</th>\n",
       "      <th>Lemak_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heavenly Blush</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A&amp;W</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A&amp;W Beef burger</td>\n",
       "      <td>342.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A&amp;W Burger cheeseburger</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A&amp;W burger mozza</td>\n",
       "      <td>550.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Food_Name  Energi  Protein  Karbohidrat_total  Lemak_total\n",
       "0           Heavenly Blush    90.0      2.0               15.0          2.5\n",
       "1                      A&W   170.0      0.0               43.0          0.0\n",
       "2          A&W Beef burger   342.0     13.0               39.0         16.0\n",
       "3  A&W Burger cheeseburger   398.0     15.0               39.0         21.0\n",
       "4         A&W burger mozza   550.0     25.0               43.0         33.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 839 entries, 0 to 838\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Food_Name          839 non-null    object \n",
      " 1   Energi             839 non-null    float64\n",
      " 2   Protein            839 non-null    float64\n",
      " 3   Karbohidrat_total  839 non-null    float64\n",
      " 4   Lemak_total        839 non-null    float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Energi     Protein  Karbohidrat_total  Lemak_total\n",
      "count   839.000000  839.000000         839.000000   839.000000\n",
      "mean    244.092718    8.104756          27.286293    10.269642\n",
      "std     236.195633   12.977977          31.643319    14.536275\n",
      "min       0.000000    0.000000           0.000000     0.000000\n",
      "25%     100.000000    1.060000           7.850000     2.000000\n",
      "50%     163.000000    4.000000          20.000000     6.000000\n",
      "75%     330.000000    9.000000          40.000000    13.645000\n",
      "max    1914.000000  170.000000         640.000000   148.000000\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Energi'] = dataframe['Energi'].astype('float')\n",
    "labels = pd.factorize(dataframe.pop('Food_Name'))[0].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical columns: 4\n",
      "Total number of columns in the feature dataframe: 4\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = dataframe.select_dtypes(include=['int64','float64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    ('scaler', preprocessing.MinMaxScaler())\n",
    "])\n",
    "\n",
    "print(\"Number of numerical columns:\", len(numeric_columns))\n",
    "print(\"Total number of columns in the feature dataframe:\", dataframe.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed features from df_features_train.shape: (839, 4) to array_features_train.shape: (839, 4)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = compose.ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_columns),\n",
    "])\n",
    "\n",
    "# Display the shapes of the training dataset for final inspection\n",
    "array_features_train = preprocessor.fit_transform(dataframe)\n",
    "print(\"Transformed features from df_features_train.shape: {} to array_features_train.shape: {}\".format(dataframe.shape, array_features_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_features_train.shape: (839, 4) array_target_train.shape: (839,)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "array_target_train = label_encoder.fit_transform(labels)\n",
    "print(\"array_features_train.shape: {} array_target_train.shape: {}\".format(array_features_train.shape, array_target_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 14s]\n",
      "accuracy: 0.08380682021379471\n",
      "\n",
      "Best accuracy So Far: 0.9389204382896423\n",
      "Total elapsed time: 00h 11m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 12ms/step - loss: 8.3031 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 4.8883 - accuracy: 0.0656\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 3.6307 - accuracy: 0.2348\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.8649 - accuracy: 0.4327\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.2649 - accuracy: 0.6174\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.8006 - accuracy: 0.7521\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.4315 - accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.1678 - accuracy: 0.8856\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.9560 - accuracy: 0.9011\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.7757 - accuracy: 0.9285\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.6368 - accuracy: 0.9297\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.5574 - accuracy: 0.9380\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5112 - accuracy: 0.9106\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5030 - accuracy: 0.9011\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4663 - accuracy: 0.9046\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4678 - accuracy: 0.8903\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4798 - accuracy: 0.8808\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4609 - accuracy: 0.8820\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4452 - accuracy: 0.8784\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4488 - accuracy: 0.8737\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4302 - accuracy: 0.8772\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4341 - accuracy: 0.8856\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4132 - accuracy: 0.8832\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4004 - accuracy: 0.8832\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3793 - accuracy: 0.8880\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3480 - accuracy: 0.8844\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3553 - accuracy: 0.8963\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3334 - accuracy: 0.8975\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.3074 - accuracy: 0.9094\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.8963\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3363 - accuracy: 0.8963\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.8999\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3185 - accuracy: 0.9011\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.9058\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2905 - accuracy: 0.9094\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2626 - accuracy: 0.9178\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2290 - accuracy: 0.9273\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2214 - accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2076 - accuracy: 0.9321\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2200 - accuracy: 0.9333\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2160 - accuracy: 0.9297\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2133 - accuracy: 0.9297\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2186 - accuracy: 0.9285\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2315 - accuracy: 0.9297\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2230 - accuracy: 0.9261\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9261\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2331 - accuracy: 0.9261\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2558 - accuracy: 0.9249\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2470 - accuracy: 0.9273\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2579 - accuracy: 0.9142\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2897 - accuracy: 0.9142\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2708 - accuracy: 0.9142\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2820 - accuracy: 0.9190\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9225\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2874 - accuracy: 0.9046\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2698 - accuracy: 0.9094\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2609 - accuracy: 0.9178\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2267 - accuracy: 0.9285\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2313 - accuracy: 0.9237\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2462 - accuracy: 0.9201\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1998 - accuracy: 0.9249\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1958 - accuracy: 0.9273\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1978 - accuracy: 0.9261\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1883 - accuracy: 0.9285\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1782 - accuracy: 0.9344\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1565 - accuracy: 0.9428\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1536 - accuracy: 0.9392\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1617 - accuracy: 0.9368\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1477 - accuracy: 0.9380\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1342 - accuracy: 0.9368\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9440\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1363 - accuracy: 0.9428\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.9464\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1280 - accuracy: 0.9523\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1243 - accuracy: 0.9487\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1336 - accuracy: 0.9499\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1394 - accuracy: 0.9452\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1334 - accuracy: 0.9487\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1274 - accuracy: 0.9547\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1242 - accuracy: 0.9523\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1275 - accuracy: 0.9487\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9499\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1312 - accuracy: 0.9487\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1256 - accuracy: 0.9487\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1202 - accuracy: 0.9487\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1244 - accuracy: 0.9487\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1369 - accuracy: 0.9535\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9464\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.9440\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1427 - accuracy: 0.9511\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1599 - accuracy: 0.9452\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1836 - accuracy: 0.9404\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1818 - accuracy: 0.9368\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1781 - accuracy: 0.9392\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2004 - accuracy: 0.9368\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2014 - accuracy: 0.9380\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2185 - accuracy: 0.9190\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2303 - accuracy: 0.9344\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1819 - accuracy: 0.9344\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_classifier\\best_model\\assets\n",
      "Total time for model fitting: 0:11:43.392044\n"
     ]
    }
   ],
   "source": [
    "start_time_module = datetime.now()\n",
    "\n",
    "auto_model = ak.StructuredDataClassifier(loss='categorical_crossentropy',\n",
    "                                         metrics=['accuracy'],\n",
    "                                         max_trials=50,\n",
    "                                         objective=keras_tuner.Objective(\"accuracy\", direction=\"max\")\n",
    "                                        )\n",
    "auto_model.fit(x=array_features_train,\n",
    "               y=array_target_train,\n",
    "               epochs=100,\n",
    "               batch_size=32,\n",
    "               verbose=1)\n",
    "print('Total time for model fitting:', (datetime.now() - start_time_module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 4)                0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 4)                9         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2560      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 839)               859975    \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 839)              0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,000\n",
      "Trainable params: 1,390,919\n",
      "Non-trainable params: 3,081\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = auto_model.export_model()\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save('saved_model/testing_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 4)                0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 4)                9         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2560      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 839)               859975    \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 839)              0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,000\n",
      "Trainable params: 1,390,919\n",
      "Non-trainable params: 3,081\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = load_model('./saved_model/testing_model_2.h5')\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[280.0,14.0,20.0,17.0]]\n",
    "test_data = preprocessor.transform(pd.DataFrame(data=array, index=np.arange(len(array)), columns=['Energi','Protein','Karbohidrat_total','Lemak_total']))\n",
    "test_prediction = (-final_model.predict(test_data)).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356 364 612  68 127]\n"
     ]
    }
   ],
   "source": [
    "print(test_prediction[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_labels = dataframecopy['Food_Name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[342.0, 13.0, 39.0, 16.0]\n"
     ]
    }
   ],
   "source": [
    "located_data = dataframecopy.loc[dataframecopy['Food_Name'] == 'A&W Beef burger']\n",
    "print([located_data['Energi'].values[0],located_data['Protein'].values[0],located_data['Karbohidrat_total'].values[0],located_data['Lemak_total'].values[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[280.0, 14.0, 20.0, 17.0]]\n",
      "Energi               170.0\n",
      "Protein               10.0\n",
      "Karbohidrat_total     17.4\n",
      "Lemak_total           13.0\n",
      "Name: 356, dtype: float64\n",
      "KFC extra crispy sayap\n",
      "[[280.0, 14.0, 20.0, 17.0]]\n",
      "Energi               120.00\n",
      "Protein                8.00\n",
      "Karbohidrat_total     13.71\n",
      "Lemak_total            8.00\n",
      "Name: 364, dtype: float64\n",
      "King's Fisher sarden goreng balado\n",
      "[[280.0, 14.0, 20.0, 17.0]]\n",
      "Energi               327.8\n",
      "Protein               19.5\n",
      "Karbohidrat_total     28.0\n",
      "Lemak_total           18.9\n",
      "Name: 612, dtype: float64\n",
      "Saladstop Tuna San\n"
     ]
    }
   ],
   "source": [
    "for i in test_prediction[0][:3]:\n",
    "    print(array)\n",
    "    print(dataframe.loc[i,:])\n",
    "    print(name_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 7.1493 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1527 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1391 - accuracy: 0.0012\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1508 - accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1425 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1677 - accuracy: 0.0012\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1565 - accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1373 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1609 - accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1388 - accuracy: 0.0012\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1355 - accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1493 - accuracy: 0.0012\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1519 - accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1404 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1482 - accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1439 - accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1485 - accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1557 - accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1530 - accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1522 - accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1273 - accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1428 - accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 7.1599 - accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1261 - accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1491 - accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1345 - accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1384 - accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1409 - accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1291 - accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "22/27 [=======================>......] - ETA: 0s - loss: 7.1525 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\BANGKIT2022\\CapstoneProject\\food_recommender_model\\model.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=1'>2</a>\u001b[0m   layers\u001b[39m.\u001b[39mNormalization(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=2'>3</a>\u001b[0m   layers\u001b[39m.\u001b[39mDense(\u001b[39m512\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=6'>7</a>\u001b[0m   layers\u001b[39m.\u001b[39mDense(\u001b[39mlen\u001b[39m(dataframe), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=7'>8</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.00000001\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=10'>11</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=11'>12</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49marray_features_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=14'>15</a>\u001b[0m           y\u001b[39m=\u001b[39;49marray_target_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=15'>16</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.CategoryEncoding(num_tokens=4),\n",
    "  layers.Normalization(),\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(1024, activation='relu'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(len(dataframe), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00000001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=array_features_train,\n",
    "          y=array_target_train,\n",
    "          epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e13f312b7c320a6140345955af31bbc32410e5c5188ccef25ae551b75cba357"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf2.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
