{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn import impute\n",
    "\n",
    "import keras_tuner\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"E:\\BANGKIT2022\\CapstoneProject\\data_gathering\\data\\cleaned_data.csv\"\n",
    "\n",
    "dataframe = pd.read_csv(csv_file, delimiter=';')\n",
    "dataframecopy = pd.read_csv(csv_file, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food_Name</th>\n",
       "      <th>Energi</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Karbohidrat_total</th>\n",
       "      <th>Lemak_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heavenly Blush</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A&amp;W</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A&amp;W Beef burger</td>\n",
       "      <td>342.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A&amp;W Burger cheeseburger</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A&amp;W burger mozza</td>\n",
       "      <td>550.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Food_Name  Energi  Protein  Karbohidrat_total  Lemak_total\n",
       "0           Heavenly Blush    90.0      2.0               15.0          2.5\n",
       "1                      A&W   170.0      0.0               43.0          0.0\n",
       "2          A&W Beef burger   342.0     13.0               39.0         16.0\n",
       "3  A&W Burger cheeseburger   398.0     15.0               39.0         21.0\n",
       "4         A&W burger mozza   550.0     25.0               43.0         33.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 839 entries, 0 to 838\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Food_Name          839 non-null    object \n",
      " 1   Energi             839 non-null    float64\n",
      " 2   Protein            839 non-null    float64\n",
      " 3   Karbohidrat_total  839 non-null    float64\n",
      " 4   Lemak_total        839 non-null    float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Energi     Protein  Karbohidrat_total  Lemak_total\n",
      "count   839.000000  839.000000         839.000000   839.000000\n",
      "mean    244.092718    8.104756          27.286293    10.269642\n",
      "std     236.195633   12.977977          31.643319    14.536275\n",
      "min       0.000000    0.000000           0.000000     0.000000\n",
      "25%     100.000000    1.060000           7.850000     2.000000\n",
      "50%     163.000000    4.000000          20.000000     6.000000\n",
      "75%     330.000000    9.000000          40.000000    13.645000\n",
      "max    1914.000000  170.000000         640.000000   148.000000\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Energi'] = dataframe['Energi'].astype('float')\n",
    "labels = pd.factorize(dataframe.pop('Food_Name'))[0].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical columns: 4\n",
      "Total number of columns in the feature dataframe: 4\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = dataframe.select_dtypes(include=['int64','float64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    ('scaler', preprocessing.MinMaxScaler())\n",
    "])\n",
    "\n",
    "print(\"Number of numerical columns:\", len(numeric_columns))\n",
    "print(\"Total number of columns in the feature dataframe:\", dataframe.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed features from df_features_train.shape: (839, 4) to array_features_train.shape: (839, 4)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = compose.ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_columns),\n",
    "])\n",
    "\n",
    "# Display the shapes of the training dataset for final inspection\n",
    "array_features_train = preprocessor.fit_transform(dataframe)\n",
    "print(\"Transformed features from df_features_train.shape: {} to array_features_train.shape: {}\".format(dataframe.shape, array_features_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_features_train.shape: (839, 4) array_target_train.shape: (839,)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "array_target_train = label_encoder.fit_transform(labels)\n",
    "print(\"array_features_train.shape: {} array_target_train.shape: {}\".format(array_features_train.shape, array_target_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 14s]\n",
      "accuracy: 0.08380682021379471\n",
      "\n",
      "Best accuracy So Far: 0.9389204382896423\n",
      "Total elapsed time: 00h 11m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 12ms/step - loss: 8.3031 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 4.8883 - accuracy: 0.0656\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 3.6307 - accuracy: 0.2348\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.8649 - accuracy: 0.4327\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.2649 - accuracy: 0.6174\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.8006 - accuracy: 0.7521\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.4315 - accuracy: 0.8367\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.1678 - accuracy: 0.8856\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.9560 - accuracy: 0.9011\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.7757 - accuracy: 0.9285\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.6368 - accuracy: 0.9297\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.5574 - accuracy: 0.9380\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5112 - accuracy: 0.9106\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.5030 - accuracy: 0.9011\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4663 - accuracy: 0.9046\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4678 - accuracy: 0.8903\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4798 - accuracy: 0.8808\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4609 - accuracy: 0.8820\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4452 - accuracy: 0.8784\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4488 - accuracy: 0.8737\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4302 - accuracy: 0.8772\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4341 - accuracy: 0.8856\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4132 - accuracy: 0.8832\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.4004 - accuracy: 0.8832\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3793 - accuracy: 0.8880\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3480 - accuracy: 0.8844\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3553 - accuracy: 0.8963\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3334 - accuracy: 0.8975\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.3074 - accuracy: 0.9094\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.8963\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3363 - accuracy: 0.8963\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.8999\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3185 - accuracy: 0.9011\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.9058\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2905 - accuracy: 0.9094\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2626 - accuracy: 0.9178\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2290 - accuracy: 0.9273\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2214 - accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2076 - accuracy: 0.9321\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2200 - accuracy: 0.9333\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2160 - accuracy: 0.9297\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2133 - accuracy: 0.9297\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2186 - accuracy: 0.9285\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2315 - accuracy: 0.9297\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2230 - accuracy: 0.9261\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9261\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2331 - accuracy: 0.9261\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2558 - accuracy: 0.9249\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2470 - accuracy: 0.9273\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2579 - accuracy: 0.9142\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2897 - accuracy: 0.9142\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2708 - accuracy: 0.9142\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2820 - accuracy: 0.9190\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9225\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2874 - accuracy: 0.9046\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2698 - accuracy: 0.9094\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2609 - accuracy: 0.9178\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2267 - accuracy: 0.9285\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2313 - accuracy: 0.9237\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2462 - accuracy: 0.9201\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1998 - accuracy: 0.9249\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1958 - accuracy: 0.9273\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1978 - accuracy: 0.9261\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1883 - accuracy: 0.9285\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1782 - accuracy: 0.9344\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1565 - accuracy: 0.9428\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1536 - accuracy: 0.9392\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1617 - accuracy: 0.9368\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1477 - accuracy: 0.9380\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1342 - accuracy: 0.9368\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9440\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1363 - accuracy: 0.9428\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.9464\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1280 - accuracy: 0.9523\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1243 - accuracy: 0.9487\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1336 - accuracy: 0.9499\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1394 - accuracy: 0.9452\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1334 - accuracy: 0.9487\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1274 - accuracy: 0.9547\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1242 - accuracy: 0.9523\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.1275 - accuracy: 0.9487\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9499\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1312 - accuracy: 0.9487\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1256 - accuracy: 0.9487\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1202 - accuracy: 0.9487\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1244 - accuracy: 0.9487\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1369 - accuracy: 0.9535\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9464\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.9440\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1427 - accuracy: 0.9511\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1599 - accuracy: 0.9452\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1836 - accuracy: 0.9404\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1818 - accuracy: 0.9368\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1781 - accuracy: 0.9392\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2004 - accuracy: 0.9368\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2014 - accuracy: 0.9380\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2185 - accuracy: 0.9190\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2303 - accuracy: 0.9344\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1819 - accuracy: 0.9344\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_classifier\\best_model\\assets\n",
      "Total time for model fitting: 0:11:43.392044\n"
     ]
    }
   ],
   "source": [
    "start_time_module = datetime.now()\n",
    "\n",
    "auto_model = ak.StructuredDataClassifier(loss='categorical_crossentropy',\n",
    "                                         metrics=['accuracy'],\n",
    "                                         max_trials=50,\n",
    "                                         objective=keras_tuner.Objective(\"accuracy\", direction=\"max\")\n",
    "                                        )\n",
    "auto_model.fit(x=array_features_train,\n",
    "               y=array_target_train,\n",
    "               epochs=100,\n",
    "               batch_size=32,\n",
    "               verbose=1)\n",
    "print('Total time for model fitting:', (datetime.now() - start_time_module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 4)                0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 4)                9         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2560      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 839)               859975    \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 839)              0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,000\n",
      "Trainable params: 1,390,919\n",
      "Non-trainable params: 3,081\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = auto_model.export_model()\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save('saved_model/testing_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 4)                0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 4)                9         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2560      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 839)               859975    \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 839)              0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,000\n",
      "Trainable params: 1,390,919\n",
      "Non-trainable params: 3,081\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = load_model('./saved_model/testing_model_2.h5')\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[400.0,15.0,25.0,17.0]]\n",
    "test_data = preprocessor.transform(pd.DataFrame(data=array, index=np.arange(len(array)), columns=['Energi','Protein','Karbohidrat_total','Lemak_total']))\n",
    "test_prediction = (-loaded_model.predict(test_data)).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166   2 710 418 449]\n"
     ]
    }
   ],
   "source": [
    "print(test_prediction[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_labels = dataframecopy['Food_Name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[342.0, 13.0, 39.0, 16.0]\n"
     ]
    }
   ],
   "source": [
    "located_data = dataframecopy.loc[dataframecopy['Food_Name'] == 'A&W Beef burger']\n",
    "print([located_data['Energi'].values[0],located_data['Protein'].values[0],located_data['Karbohidrat_total'].values[0],located_data['Lemak_total'].values[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400.0, 15.0, 25.0, 17.0]]\n",
      "Energi               370.0\n",
      "Protein               16.0\n",
      "Karbohidrat_total     22.0\n",
      "Lemak_total           17.0\n",
      "Name: 166, dtype: float64\n",
      "Domino Pizza Meatzza\n",
      "[[400.0, 15.0, 25.0, 17.0]]\n",
      "Energi               342.0\n",
      "Protein               13.0\n",
      "Karbohidrat_total     39.0\n",
      "Lemak_total           16.0\n",
      "Name: 2, dtype: float64\n",
      "A&W Beef burger\n",
      "[[400.0, 15.0, 25.0, 17.0]]\n",
      "Energi               250.0\n",
      "Protein                9.0\n",
      "Karbohidrat_total     23.0\n",
      "Lemak_total            8.0\n",
      "Name: 710, dtype: float64\n",
      "Starbucks iced caffe mocha (whole milk\n",
      "[[400.0, 15.0, 25.0, 17.0]]\n",
      "Energi               300.0\n",
      "Protein               15.0\n",
      "Karbohidrat_total     20.0\n",
      "Lemak_total           12.0\n",
      "Name: 418, dtype: float64\n",
      "Mcdonald Cheeseburger\n",
      "[[400.0, 15.0, 25.0, 17.0]]\n",
      "Energi               350.0\n",
      "Protein               10.0\n",
      "Karbohidrat_total     40.0\n",
      "Lemak_total           13.0\n",
      "Name: 449, dtype: float64\n",
      "Mie Sedaap selection korean sicy soup\n"
     ]
    }
   ],
   "source": [
    "for i in test_prediction[0][:5]:\n",
    "    print(array)\n",
    "    print(dataframe.loc[i,:])\n",
    "    print(name_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 7.1493 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1527 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1391 - accuracy: 0.0012\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1508 - accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1425 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1677 - accuracy: 0.0012\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1565 - accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1373 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1609 - accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1388 - accuracy: 0.0012\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1355 - accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1493 - accuracy: 0.0012\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1519 - accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1404 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1482 - accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1439 - accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1485 - accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1557 - accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1530 - accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1522 - accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1273 - accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1428 - accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 7.1599 - accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1261 - accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1491 - accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1345 - accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1384 - accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 7.1409 - accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 7.1291 - accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "22/27 [=======================>......] - ETA: 0s - loss: 7.1525 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\BANGKIT2022\\CapstoneProject\\food_recommender_model\\model.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=1'>2</a>\u001b[0m   layers\u001b[39m.\u001b[39mNormalization(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=2'>3</a>\u001b[0m   layers\u001b[39m.\u001b[39mDense(\u001b[39m512\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=6'>7</a>\u001b[0m   layers\u001b[39m.\u001b[39mDense(\u001b[39mlen\u001b[39m(dataframe), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=7'>8</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.00000001\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=10'>11</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=11'>12</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49marray_features_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=14'>15</a>\u001b[0m           y\u001b[39m=\u001b[39;49marray_target_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/BANGKIT2022/CapstoneProject/food_recommender_model/model.ipynb#ch0000018?line=15'>16</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/ACER/miniconda3/envs/tf2.8/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.CategoryEncoding(num_tokens=4),\n",
    "  layers.Normalization(),\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(1024, activation='relu'),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(len(dataframe), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00000001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=array_features_train,\n",
    "          y=array_target_train,\n",
    "          epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain models with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"E:\\BANGKIT2022\\CapstoneProject\\data_gathering\\data\\cleaned_data.csv\"\n",
    "\n",
    "dataframe1 = pd.read_csv(csv_file, delimiter=';')\n",
    "dataframe2 = pd.read_csv(csv_file, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Heavenly Blush\n",
       "1                                           A&W\n",
       "2                               A&W Beef burger\n",
       "3                       A&W Burger cheeseburger\n",
       "4                              A&W burger mozza\n",
       "                         ...                   \n",
       "834    Yoshinoya Veggie beef bowl (Reguler bowl\n",
       "835                       You C100 Orange water\n",
       "836                     You C1000 vitamin apple\n",
       "837                     You C1000 vitamin lemon\n",
       "838                    You C1000 vitamin orange\n",
       "Name: Food_Name, Length: 839, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe1.pop(\"Food_Name\")\n",
    "dataframe2.pop(\"Food_Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataframe1.columns:\n",
    "    dataframe1[i] = dataframe1[i].apply(lambda x:x*0.9)\n",
    "    dataframe2[i] = dataframe2[i].apply(lambda x:x*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1['Energi'] = dataframe1['Energi'].astype('float')\n",
    "dataframe2['Energi'] = dataframe2['Energi'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_features_train1 = preprocessor.fit_transform(dataframe1)\n",
    "array_features_train2 = preprocessor.fit_transform(dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('./saved_model/testing_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27/27 [==============================] - 1s 10ms/step - loss: 1.6036 - accuracy: 0.4875\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3028 - accuracy: 0.5876\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1266 - accuracy: 0.5971\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 1.3082 - accuracy: 0.5244\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 1.3152 - accuracy: 0.5542\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2303 - accuracy: 0.5542\n",
      "Epoch 7/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5366 - accuracy: 0.4982\n",
      "Epoch 8/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3687 - accuracy: 0.5435\n",
      "Epoch 9/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2130 - accuracy: 0.5864\n",
      "Epoch 10/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4019 - accuracy: 0.5423\n",
      "Epoch 11/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4242 - accuracy: 0.5364\n",
      "Epoch 12/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2156 - accuracy: 0.6007\n",
      "Epoch 13/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3464 - accuracy: 0.5447\n",
      "Epoch 14/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3929 - accuracy: 0.5423\n",
      "Epoch 15/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2670 - accuracy: 0.5459\n",
      "Epoch 16/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.1160 - accuracy: 0.6114\n",
      "Epoch 17/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2123 - accuracy: 0.5638\n",
      "Epoch 18/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2316 - accuracy: 0.5793\n",
      "Epoch 19/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2421 - accuracy: 0.5733\n",
      "Epoch 20/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2998 - accuracy: 0.5650\n",
      "Epoch 21/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1724 - accuracy: 0.6091\n",
      "Epoch 22/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2060 - accuracy: 0.5888\n",
      "Epoch 23/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1532 - accuracy: 0.5936\n",
      "Epoch 24/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2102 - accuracy: 0.5828\n",
      "Epoch 25/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2135 - accuracy: 0.5697\n",
      "Epoch 26/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1588 - accuracy: 0.5864\n",
      "Epoch 27/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.6093 - accuracy: 0.5471\n",
      "Epoch 28/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1318 - accuracy: 0.5936\n",
      "Epoch 29/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2087 - accuracy: 0.5924\n",
      "Epoch 30/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4829 - accuracy: 0.5745\n",
      "Epoch 31/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5017 - accuracy: 0.5042\n",
      "Epoch 32/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1761 - accuracy: 0.5983\n",
      "Epoch 33/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1592 - accuracy: 0.5948\n",
      "Epoch 34/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1314 - accuracy: 0.6067\n",
      "Epoch 35/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1143 - accuracy: 0.6055\n",
      "Epoch 36/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2814 - accuracy: 0.5423\n",
      "Epoch 37/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0971 - accuracy: 0.5900\n",
      "Epoch 38/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.2038 - accuracy: 0.5971\n",
      "Epoch 39/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3247 - accuracy: 0.5399\n",
      "Epoch 40/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1810 - accuracy: 0.5900\n",
      "Epoch 41/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4220 - accuracy: 0.5232\n",
      "Epoch 42/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4590 - accuracy: 0.5375\n",
      "Epoch 43/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2255 - accuracy: 0.5959\n",
      "Epoch 44/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1592 - accuracy: 0.5709\n",
      "Epoch 45/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2666 - accuracy: 0.5816\n",
      "Epoch 46/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1993 - accuracy: 0.5662\n",
      "Epoch 47/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1917 - accuracy: 0.5816\n",
      "Epoch 48/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1785 - accuracy: 0.5888\n",
      "Epoch 49/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1824 - accuracy: 0.5983\n",
      "Epoch 50/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2749 - accuracy: 0.5542\n",
      "Epoch 51/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2868 - accuracy: 0.5697\n",
      "Epoch 52/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2423 - accuracy: 0.5483\n",
      "Epoch 53/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3011 - accuracy: 0.5638\n",
      "Epoch 54/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2453 - accuracy: 0.5733\n",
      "Epoch 55/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2753 - accuracy: 0.5578\n",
      "Epoch 56/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2695 - accuracy: 0.6007\n",
      "Epoch 57/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0810 - accuracy: 0.6031\n",
      "Epoch 58/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5080 - accuracy: 0.5292\n",
      "Epoch 59/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3523 - accuracy: 0.5435\n",
      "Epoch 60/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1555 - accuracy: 0.5793\n",
      "Epoch 61/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1493 - accuracy: 0.6055\n",
      "Epoch 62/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1966 - accuracy: 0.5542\n",
      "Epoch 63/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1879 - accuracy: 0.5757\n",
      "Epoch 64/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1134 - accuracy: 0.6234\n",
      "Epoch 65/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2311 - accuracy: 0.5852\n",
      "Epoch 66/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2310 - accuracy: 0.5733\n",
      "Epoch 67/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2321 - accuracy: 0.5924\n",
      "Epoch 68/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3360 - accuracy: 0.5483\n",
      "Epoch 69/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3010 - accuracy: 0.5638\n",
      "Epoch 70/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2699 - accuracy: 0.5638\n",
      "Epoch 71/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3864 - accuracy: 0.5626\n",
      "Epoch 72/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0397 - accuracy: 0.6126\n",
      "Epoch 73/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4385 - accuracy: 0.5602\n",
      "Epoch 74/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1489 - accuracy: 0.5852\n",
      "Epoch 75/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4211 - accuracy: 0.5471\n",
      "Epoch 76/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1963 - accuracy: 0.5805\n",
      "Epoch 77/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4795 - accuracy: 0.5113\n",
      "Epoch 78/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1162 - accuracy: 0.6091\n",
      "Epoch 79/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1551 - accuracy: 0.5828\n",
      "Epoch 80/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2751 - accuracy: 0.5709\n",
      "Epoch 81/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3683 - accuracy: 0.5495\n",
      "Epoch 82/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0124 - accuracy: 0.6389\n",
      "Epoch 83/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2027 - accuracy: 0.5733\n",
      "Epoch 84/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2280 - accuracy: 0.5995\n",
      "Epoch 85/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3799 - accuracy: 0.5423\n",
      "Epoch 86/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1308 - accuracy: 0.5995\n",
      "Epoch 87/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1742 - accuracy: 0.6043\n",
      "Epoch 88/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0240 - accuracy: 0.6174\n",
      "Epoch 89/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1831 - accuracy: 0.5733\n",
      "Epoch 90/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0193 - accuracy: 0.6472\n",
      "Epoch 91/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2472 - accuracy: 0.5781\n",
      "Epoch 92/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1979 - accuracy: 0.5745\n",
      "Epoch 93/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1463 - accuracy: 0.5662\n",
      "Epoch 94/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1478 - accuracy: 0.6353\n",
      "Epoch 95/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3572 - accuracy: 0.5530\n",
      "Epoch 96/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0951 - accuracy: 0.6126\n",
      "Epoch 97/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1451 - accuracy: 0.5936\n",
      "Epoch 98/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4459 - accuracy: 0.5411\n",
      "Epoch 99/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1662 - accuracy: 0.5971\n",
      "Epoch 100/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1296 - accuracy: 0.6162\n",
      "Epoch 101/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.3159 - accuracy: 0.5673\n",
      "Epoch 102/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4730 - accuracy: 0.5387\n",
      "Epoch 103/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2057 - accuracy: 0.5852\n",
      "Epoch 104/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.6260 - accuracy: 0.4875\n",
      "Epoch 105/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1764 - accuracy: 0.5721\n",
      "Epoch 106/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1809 - accuracy: 0.5816\n",
      "Epoch 107/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0828 - accuracy: 0.6138\n",
      "Epoch 108/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2022 - accuracy: 0.5888\n",
      "Epoch 109/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4027 - accuracy: 0.5971\n",
      "Epoch 110/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1815 - accuracy: 0.5805\n",
      "Epoch 111/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1504 - accuracy: 0.6186\n",
      "Epoch 112/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1865 - accuracy: 0.5769\n",
      "Epoch 113/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1682 - accuracy: 0.6031\n",
      "Epoch 114/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0823 - accuracy: 0.6293\n",
      "Epoch 115/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.0870 - accuracy: 0.6234\n",
      "Epoch 116/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.4602 - accuracy: 0.5244\n",
      "Epoch 117/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1744 - accuracy: 0.6126\n",
      "Epoch 118/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1107 - accuracy: 0.6031\n",
      "Epoch 119/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1902 - accuracy: 0.5614\n",
      "Epoch 120/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1788 - accuracy: 0.5900\n",
      "Epoch 121/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0538 - accuracy: 0.6222\n",
      "Epoch 122/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1076 - accuracy: 0.6126\n",
      "Epoch 123/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0898 - accuracy: 0.6365\n",
      "Epoch 124/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2765 - accuracy: 0.5495\n",
      "Epoch 125/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1693 - accuracy: 0.5757\n",
      "Epoch 126/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2422 - accuracy: 0.5662\n",
      "Epoch 127/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1238 - accuracy: 0.5983\n",
      "Epoch 128/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1567 - accuracy: 0.5876\n",
      "Epoch 129/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2498 - accuracy: 0.5614\n",
      "Epoch 130/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0442 - accuracy: 0.6091\n",
      "Epoch 131/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1413 - accuracy: 0.6055\n",
      "Epoch 132/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1413 - accuracy: 0.5876\n",
      "Epoch 133/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2510 - accuracy: 0.5483\n",
      "Epoch 134/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2677 - accuracy: 0.5733\n",
      "Epoch 135/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3317 - accuracy: 0.5590\n",
      "Epoch 136/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4453 - accuracy: 0.5459\n",
      "Epoch 137/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2302 - accuracy: 0.5805\n",
      "Epoch 138/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2252 - accuracy: 0.5709\n",
      "Epoch 139/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1291 - accuracy: 0.5971\n",
      "Epoch 140/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1623 - accuracy: 0.5864\n",
      "Epoch 141/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1431 - accuracy: 0.5876\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0725 - accuracy: 0.6055\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0379 - accuracy: 0.6400\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2105 - accuracy: 0.5840\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2516 - accuracy: 0.5638\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2307 - accuracy: 0.5697\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1697 - accuracy: 0.5840\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1599 - accuracy: 0.6091\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2774 - accuracy: 0.5733\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2736 - accuracy: 0.5352\n",
      "Epoch 151/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9400 - accuracy: 0.6496\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1410 - accuracy: 0.5959\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1738 - accuracy: 0.6186\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2656 - accuracy: 0.5888\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2194 - accuracy: 0.5638\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2470 - accuracy: 0.5900\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2018 - accuracy: 0.5840\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.1959 - accuracy: 0.5924\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3458 - accuracy: 0.5793\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2256 - accuracy: 0.5554\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9803 - accuracy: 0.6675\n",
      "Epoch 162/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0078 - accuracy: 0.6150\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1926 - accuracy: 0.5840\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2771 - accuracy: 0.5745\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2894 - accuracy: 0.5626\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2745 - accuracy: 0.5781\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1222 - accuracy: 0.5816\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1885 - accuracy: 0.5638\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3195 - accuracy: 0.5507\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4032 - accuracy: 0.5447\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2394 - accuracy: 0.5566\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1105 - accuracy: 0.6222\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2251 - accuracy: 0.6103\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2725 - accuracy: 0.5721\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1980 - accuracy: 0.6055\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3210 - accuracy: 0.5733\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1096 - accuracy: 0.6377\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1561 - accuracy: 0.6174\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1531 - accuracy: 0.6210\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3416 - accuracy: 0.5423\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1474 - accuracy: 0.6150\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.8730 - accuracy: 0.6734\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0567 - accuracy: 0.6341\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3303 - accuracy: 0.5423\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1712 - accuracy: 0.5912\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1737 - accuracy: 0.5876\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2848 - accuracy: 0.5709\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1986 - accuracy: 0.5638\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1992 - accuracy: 0.5769\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0119 - accuracy: 0.6293\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0157 - accuracy: 0.6424\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9084 - accuracy: 0.6698\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2143 - accuracy: 0.5995\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3339 - accuracy: 0.5435\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1463 - accuracy: 0.6186\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3323 - accuracy: 0.5602\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1523 - accuracy: 0.5924\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0380 - accuracy: 0.6186\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2102 - accuracy: 0.6114\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1721 - accuracy: 0.5769\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.2032 - accuracy: 0.5852\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1075 - accuracy: 0.6150\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0045 - accuracy: 0.6424\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1194 - accuracy: 0.6067\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2307 - accuracy: 0.5888\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2063 - accuracy: 0.5876\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1291 - accuracy: 0.6210\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.3213 - accuracy: 0.5638\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2903 - accuracy: 0.5566\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1559 - accuracy: 0.6043\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1938 - accuracy: 0.5793\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0706 - accuracy: 0.6222\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1506 - accuracy: 0.5828\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0630 - accuracy: 0.6293\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3152 - accuracy: 0.5614\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1016 - accuracy: 0.6436\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3390 - accuracy: 0.5793\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3703 - accuracy: 0.5530\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0280 - accuracy: 0.6222\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1646 - accuracy: 0.6138\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3273 - accuracy: 0.5638\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3374 - accuracy: 0.5662\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2202 - accuracy: 0.5995\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1345 - accuracy: 0.6031\n",
      "Epoch 225/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0082 - accuracy: 0.6544\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2241 - accuracy: 0.5828\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1474 - accuracy: 0.5983\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0110 - accuracy: 0.6317\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3979 - accuracy: 0.5316\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1987 - accuracy: 0.5816\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2630 - accuracy: 0.5876\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1588 - accuracy: 0.5781\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9250 - accuracy: 0.6663\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1310 - accuracy: 0.6126\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0284 - accuracy: 0.6365\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0748 - accuracy: 0.6234\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2999 - accuracy: 0.5816\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.2429 - accuracy: 0.5971\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2471 - accuracy: 0.6067\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2463 - accuracy: 0.5590\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0835 - accuracy: 0.6317\n",
      "Epoch 242/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2473 - accuracy: 0.5936\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1643 - accuracy: 0.5840\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.1959 - accuracy: 0.6043\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9710 - accuracy: 0.6472\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0095 - accuracy: 0.6150\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2096 - accuracy: 0.5781\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9940 - accuracy: 0.6710\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9963 - accuracy: 0.6710\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1627 - accuracy: 0.6114\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9649 - accuracy: 0.6639\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1149 - accuracy: 0.6317\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2564 - accuracy: 0.5781\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2373 - accuracy: 0.5983\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1783 - accuracy: 0.5900\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1793 - accuracy: 0.5769\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0822 - accuracy: 0.6210\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.8288 - accuracy: 0.7104\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0654 - accuracy: 0.6377\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1297 - accuracy: 0.5709\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2661 - accuracy: 0.5959\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.3186 - accuracy: 0.5721\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3775 - accuracy: 0.5852\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0600 - accuracy: 0.6198\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.3976 - accuracy: 0.5828\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0801 - accuracy: 0.6019\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2038 - accuracy: 0.6031\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.8766 - accuracy: 0.6889\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2515 - accuracy: 0.5542\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9674 - accuracy: 0.6496\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0950 - accuracy: 0.6138\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1453 - accuracy: 0.6186\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2889 - accuracy: 0.5697\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1954 - accuracy: 0.5936\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1626 - accuracy: 0.6067\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0809 - accuracy: 0.6365\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0058 - accuracy: 0.6698\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1914 - accuracy: 0.6019\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2535 - accuracy: 0.5709\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0395 - accuracy: 0.6412\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2116 - accuracy: 0.6067\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0926 - accuracy: 0.6257\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0420 - accuracy: 0.6222\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0288 - accuracy: 0.6269\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0335 - accuracy: 0.6007\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.0677 - accuracy: 0.6257\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1550 - accuracy: 0.6043\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0712 - accuracy: 0.6222\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1574 - accuracy: 0.5995\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1047 - accuracy: 0.5948\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9979 - accuracy: 0.6389\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0870 - accuracy: 0.6150\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0651 - accuracy: 0.6257\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.9154 - accuracy: 0.6687\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2761 - accuracy: 0.5650\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2109 - accuracy: 0.5805\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.9530 - accuracy: 0.6651\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0131 - accuracy: 0.6341\n",
      "Epoch 299/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1453 - accuracy: 0.6412\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0279 - accuracy: 0.6377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6a8728d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "loaded_model.fit(x=array_features_train2,\n",
    "               y=array_target_train,\n",
    "               epochs=300,\n",
    "               batch_size=32,\n",
    "               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.save('saved_model/testing_model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e13f312b7c320a6140345955af31bbc32410e5c5188ccef25ae551b75cba357"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf2.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
